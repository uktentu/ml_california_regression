# ğŸ¡ California Housing Regression â€“ MLOps Project

Predict **`median_house_value`** using the [California Housing dataset](https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset).  
This repo demonstrates a full **MLOps pipeline** with data versioning, experiment tracking, API serving, Dockerization, CI/CD, and monitoring.

---

## ğŸ“‚ Project Structure

```
.
â”œâ”€â”€ api/                  # FastAPI app
â”‚   â”œâ”€â”€ main.py           # REST endpoints
â”‚   â””â”€â”€ schemas.py        # Pydantic models (input validation)
â”œâ”€â”€ src/                  # ML pipeline code
â”‚   â”œâ”€â”€ prep_data.py      # preprocessing (scaler + one-hot encoder)
â”‚   â”œâ”€â”€ train.py          # training + MLflow logging
â”‚   â”œâ”€â”€ evaluate.py       # evaluation
â”‚   â””â”€â”€ utils.py          # logging + DB utils
â”œâ”€â”€ data/                 # dataset (DVC tracked)
â”‚   â””â”€â”€ cal_housing.csv
â”œâ”€â”€ models/               # local saved models
â”œâ”€â”€ logs/                 # log files (app.log)
â”œâ”€â”€ db/                   # SQLite DB (api_logs, train_runs)
â”œâ”€â”€ .github/workflows/ci.yml  # CI/CD pipeline
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ dvc.yaml              # optional DVC pipeline
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ”§ Tech Stack

- **Data & Code Versioning** â†’ Git + [DVC](https://dvc.org/)
- **Experiment Tracking** â†’ [MLflow](https://mlflow.org/) (metrics + model registry)
- **Model Serving** â†’ [FastAPI](https://fastapi.tiangolo.com/) + Pydantic
- **Containerization** â†’ Docker
- **CI/CD** â†’ GitHub Actions
- **Logging & Storage** â†’ Python logging + SQLite
- **Monitoring** â†’ Prometheus + Grafana (optional)

---

## âš™ï¸ Setup

### 1. Clone repo

```bash
git clone https://github.com/<your-username>/ml_california_regression.git
cd ml_california_regression
```

### 2. Create env & install deps

```bash
python -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
```

### 3. (Optional) Initialize DVC

```bash
dvc init
dvc add data/cal_housing.csv
git add data/.gitignore data/cal_housing.csv.dvc dvc.yaml
git commit -m "Track dataset with DVC"
```

---

## ğŸ“Š Training & Experiment Tracking

### Train model (Linear Regression / Random Forest)

```bash
python src/train.py --model rf
```

### Evaluate model

```bash
python src/evaluate.py
```

### Launch MLflow UI

```bash
mlflow ui --backend-store-uri ./mlruns
```

Visit â†’ [http://127.0.0.1:5000](http://127.0.0.1:5000)  
Youâ€™ll see:

- Params (`model=rf`)
- Metrics (`rmse`, `mae`, `r2`)
- Artifacts (`model.pkl`, signature, conda env)
- Model Registry (`housing_model` with version history)

---

## ğŸŒ API Service

### Run FastAPI locally

```bash
uvicorn api.main:app --reload
```

### Endpoints

- `GET /health` â†’ health check
- `POST /predict` â†’ predict house value
- `GET /logs` â†’ last 50 log lines (plain text)
- `GET /logs/db` â†’ logs from SQLite (JSON)
- `GET /logs/db/html` â†’ logs as an HTML table
- `GET /metrics` â†’ Prometheus metrics

### Example request

```bash
curl -X POST http://127.0.0.1:8000/predict -H "Content-Type: application/json" -d '{
  "longitude": -122.23,
  "latitude": 37.88,
  "housing_median_age": 41,
  "total_rooms": 880,
  "total_bedrooms": 129,
  "population": 322,
  "households": 126,
  "median_income": 8.3252,
  "ocean_proximity": "<1H OCEAN"
}'
```

Response:

```json
{
  "prediction": 256789.23,
  "latency_ms": 12.45
}
```

---

## ğŸ³ Docker

### Build

```bash
docker build -t housing-api:latest .
```

### Run

```bash
docker run -p 8000:8000 housing-api:latest
```

Visit â†’ [http://127.0.0.1:8000/docs](http://127.0.0.1:8000/docs)

---

## ğŸš€ CI/CD (GitHub Actions)

The pipeline (`.github/workflows/ci.yml`) runs on every push/PR:

1. Install deps
2. Lint Python files
3. Train model (`src/train.py`)
4. Evaluate model (`src/evaluate.py`)
5. Build Docker image
6. (Optional) Push to GHCR or Docker Hub

### Enable GHCR push

1. Add secret `GHCR_PAT` (or use built-in `GITHUB_TOKEN` with `packages: write`)
2. Image will be available at:
   ```
   ghcr.io/<owner>/<repo>:latest
   ```

---

## ğŸ“ˆ Monitoring (Optional)

- **Prometheus** scrapes metrics from `/metrics`.
- **Grafana** dashboards â†’ request count, prediction latency, error rates, distribution.

---

## ğŸ“‘ Logs

- File logs: `logs/app.log`
- Structured logs in SQLite: `db/app.db` (`api_logs`, `train_runs`)

---

## âœ… Next Steps

- Connect Prometheus + Grafana for full monitoring
- Add pytest test suite (`tests/`)
- Extend CI to auto-promote best model in MLflow registry
- Deploy API with Kubernetes or Docker Compose

---

## âœ¨ Summary

This repo shows how to take a **simple regression task** and wrap it in **full MLOps best practices**:

- Reproducible data & code (Git + DVC)
- Experiment tracking + registry (MLflow)
- Scalable API (FastAPI + Docker)
- Automated pipeline (GitHub Actions)
- Observability (logs, SQLite, Prometheus/Grafana)
